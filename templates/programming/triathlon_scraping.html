{% extends "base.html" %}
{% block content %}

                    <p class="tab"><b>This</b> post combines my interest in triathlon with programming.  Triathlons involve swimming, biking and running (in that order) various distances.  A well run race involves accurately balancing the speed / power exertion in each event.  This dynamic is most apparent in the tradeoff between bike and run times.  Biking too hard can yield small gains which are two fold lost on the run; alternatively, biking too slow can put you at the start of the run with an impossible gap to make up.  Well done races require the perfect balance.</p>

                    
                    <p class="tab"><b>Here</b>, I analyze the bike and run times for Ironman Lake Placid from 2014.  I'm signed up for this race in 2015, and it would be interesting to see how the field allocated their effort across the two sports.  I built a webscraper in python (technical details below) to rip the results from <a href="http://www.ironman.com/triathlon/events/americas/ironman/lake-placid/results.aspx#axzz3e1aPJ9Xg" target="_blank" style="target-new: tab;">Here</a> and put them in a CSV file.  A graph with run splits on one axis and bike splits on another could possibly yeild some insights</p>

                    <hr>


                    <p class="tab"><b>The</b> first few lines of the resulting CSV look like this (there are 2757 entries):</p>


                    <a href="https://s3-us-west-2.amazonaws.com/david-website/Programming/triathlon_scraping_part_I/cropped_ss.png">
                    <img class="embed_img" src="https://s3-us-west-2.amazonaws.com/david-website/Programming/triathlon_scraping_part_I/cropped_ss.png">
               </a>
               <p class="tab"><B>Note**:</B> Race day storms prevented non-pros from doing the full swim, hence most of the swim times are around :30 rather than the normal 1:00; the winner in row 9 because the 8 amateurs above him only have times for half the swim. </p>


                    <p class="tab"><B>Each</B> row represents an individual in order of finishing time, the  columns are last-name, first-name, swim split, bike split and run split.  Transistion times (time required to change cloths between sports) have been omitted.  Graphing column D (bike) against column E (run) yeilds the graph of interest:</p>

                    <a href="https://s3-us-west-2.amazonaws.com/david-website/Programming/triathlon_scraping_part_I/graph_best.png">
                    <img class="embed_img" src="https://s3-us-west-2.amazonaws.com/david-website/Programming/triathlon_scraping_part_I/graph_best.png">
               </a>

                    <p class="tab"><B>Analysis</B> time!  Great, now we are getting something sexy.  This scatter plot has bike splits as the x axis and run splits as the y axis.  Obviously, lower times for both is better; we see our champ, Kyle Buckingham in the far bottom left corner.  </p>

                    <p class="tab"><B>One</B> can imagine that a hypothetical line (or perhaps curve) exists where a point represents an optimally balanced race and each different point represents optimally balanced races at different levels of fitness.  The line on the graph is most likely not this, but a good aproximation.  The values for this line indicate the average tradeoff; taking a bike time, multiplying it by .93 and subtracting 1:37 should be a good guess for their run.  </p>

                    <p class="tab"><B>The</B> cirlce indicates approximately where I hope to find myself.  This will be my first full, and I'm very scared about going out too hard.  My plan of attack: I'm hoping to be around 11:00 and plan on going quite slow for the swim, possibly as slow as 1:10-1:20.  Add in 15 minutes of transitions and I'm left with ~9:30 (570 minutes) to spread between the run and bike.  Using the best fit and solving the system of equations: Bike = 345.59, Run = 224.40</p>

                    <p class="tab"><B>This</B> rough estimate implies a 5:45 bike (19.3 mph) and 3:44 (8:35 min/mile) marathon.  Given that my recent half iron was at 22.5 mph and 7:10 respectively; its not an absurd goal; though IMLP is a much harder course than patriot HIM.  A 1:16 swim and 11 minutes of total transition would give me ~11:00:42, which seems doable.</p>

                    <p class="tab"><B>The</B> data can be cut many different ways.  I could have made each athlete an instance of a class, so I could analyze by age group as well.  Here is finishing place vs total time.  An interesting logistic curve:</p>

                    <a href="https://s3-us-west-2.amazonaws.com/david-website/Programming/triathlon_scraping_part_I/time_vs_place.png">
                    <img class="embed_img" src="https://s3-us-west-2.amazonaws.com/david-website/Programming/triathlon_scraping_part_I/time_vs_place.png">
               </a>



                    <p class="tab"><B>Technical Details:</B> </p>

                    <p class="tab"><B>The </B>first pass at generating the data was done the hard, inefficient way: I built a python scraper which searched strings manually.  The second pass (further down) was much more elegant using the <a href="http://www.crummy.com/software/BeautifulSoup/bs4/doc/" target="_blank" style="target-new: tab;">Beautiful Soup</a> library</p>
                    </p>

                    <p class="tab"><B>Bad brute force method:</B> <a href="https://github.com/terwilld/Brute-force-IMLP-scraping/blob/master/Brute_force_IMLP.py" target="_blank" style="target-new: tab;">Code Here</a></p>
                    </p>


<pre class="prettyprint lang-python">
from bs4 import BeautifulSoup
import csv,requests,time,datetime,urllib,copy

r = requests.get('http://www.ironman.com/triathlon/events/americas/ironman/lake-placid/results.aspx#axzz3ZGxvpGki')
first_index=r.text.index('<tbody>')
second_index=r.text.index('</tbody>')
current_results_table=r.text[first_index:second_index]

for i in range(0,20):
    try:
        first_tr_index=current_results_table.index('<tr>')
        second_tr_index=current_results_table.index('</tr>')
        un_cleaned_athlete_html+=[current_results_table[first_tr_index:(second_tr_index+len('</tr>'))]]
          #once athelte data added, remove from raw html
          current_results_table=current_results_table[(second_tr_index+len('</tr>')):]
     except:
          x=2

          # All Remaining pages for IMLP 2014 results
          # Pages 2-139
     for k in range(2,139): #139= true max possibly make a large max and an except break
          #print k,len(un_cleaned_athlete_html),'page','len uncleaned_html'
          time.sleep(.100)
     r = requests.get('http://www.ironman.com/triathlon/events/americas/ironman/lake-placid/results.aspx?p='+str(k)+'#axzz3ZGxvpGki')
     # Essentially repeat the steps done above for the first page
     first_index=r.text.index('<tbody>')
     second_index=r.text.index('</tbody>')
     current_results_table=r.text[first_index:second_index]
     for i in range(0,20):
          try:
               first_tr_index=current_results_table.index('<tr>')
               second_tr_index=current_results_table.index('</tr>')
               un_cleaned_athlete_html+=[current_results_table[first_tr_index:(second_tr_index+len('</tr>'))]]
                    #once athelte data added, remove from raw html
               current_results_table=current_results_table[(second_tr_index+len('</tr>')):]
          except:
               x=2
</pre>


                    <p class="tab"><B>The</B> snippit above contains the meat of the logic.  The real inefficiency is from the (redacted) series of methods which took up ~60 lines.  If you want to make fun of my horribly ugly code, feel free to check out the full code (linked above) on github.   The general plan of attack is:  I get the HTML stored as a string using requests, I know the table containing all my data is bracketed by tr tags, I nuke everything else, then extract everything else from the nested HTML tags.  The first page has a unique URL while pages 2-139 are built using a template.  It was much better done when I refactored using BS4! </p>
                    </p>

                    <p class="tab"><B>More</B> elegant (less ugly) refactor using BS4:  <a href="https://github.com/terwilld/Brute-force-IMLP-scraping/blob/master/IMLP%20scrap%20BS4.py" target="_blank" style="target-new: tab;">Code Here</a></p>
                    </p>


<pre class="prettyprint lang-python">
from bs4 import BeautifulSoup
import requests,time,csv,copy
     #Get page one
r = requests.get('http://www.ironman.com/triathlon/events/americas/ironman/lake-placid/results.aspx#axzz3ZGxvpGki')
raw_html=r.text
     #Soupify
soup = BeautifulSoup(raw_html)
#Make list of all elements surrounded by td tags. This is our lowest denominator
results=soup.findAll('td')
counter=1
list_of_people=[]
person=[]
for x in results:
#print x, 'counter',counter,x.text
     if counter == 1 or counter == 6 or counter == 7 or counter == 8 or counter == 9:
          person+=[x.text]
     counter+=1
     if counter>10:
          counter-=10
          list_of_people+=[person]
          person=[]
for k in range(2,139): #139= true max possibly make a large max and an except break
     #print k,len(list_of_people),'page','len uncleaned_html'
     time.sleep(0.100)
     r = requests.get('http://www.ironman.com/triathlon/events/americas/ironman/lake-placid/results.aspx?p='+str(k)+'#axzz3ZGxvpGki')
          # Essentially repeat the steps done above for the first page
     raw_html=r.text
          #Soupify
     soup = BeautifulSoup(raw_html)
          #Make list of all elements surrounded by td tags. This is our lowest denominator
          results=soup.findAll('td')
     counter=1
     person=[]
     for x in results:
          #print x, 'counter',counter,x.text
          if counter == 1 or counter == 6 or counter == 7 or counter == 8 or counter == 9:
               person+=[x.text]
          counter+=1
          if counter>10:
               counter-=10
               list_of_people+=[person]
               person=[]
</pre>


                    <p class="tab"><B>This</B> snippit essentially replaced the previously omitted increadibly cumbersome methods.  BS4 goes though a parse tree, and prints out all results within a td tag, each athlete has 10 such tags associated with them, my data of interest is in tags 1 and 6-9.  Reset the counter every iteration, and presto! Same results with 50% less code.  [Yes I know there are better ways to use BS4, but I got those working fairly quickly so decided not to much prettier with correct parents and such] </p>
                    </p>



<p class="tab">Awesome!</p>
{% endblock %}